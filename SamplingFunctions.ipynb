{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debg48/pytorch_for_beginners/blob/main/SamplingFunctions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK8tyHPOI6Os"
      },
      "source": [
        "#  PyTorch Functions for Sampling\n",
        "\n",
        "\n",
        "### PyTorch\n",
        "\n",
        "PyTorch is an open source deep learning framework built to be flexible and modular for research, with the stability and support needed for production deployment. PyTorch provides a Python package for high-level features like tensor computation (like NumPy) with strong GPU acceleration and TorchScript for an easy transition between eager mode and graph mode. With the latest release of PyTorch, the framework provides graph-based execution, distributed training, mobile deployment, and quantization.\n",
        "\n",
        "### Random Sampling\n",
        "\n",
        "Random sampling is a part of the sampling technique in which each sample has an equal probability of being chosen. A sample chosen randomly is meant to be an unbiased representation of the total population. If for some reasons, the sample does not represent the population, the variation is called a sampling error.\n",
        "\n",
        "Random sampling is one of the simplest forms of collecting data from the total population. Under random sampling, each member of the subset carries an equal opportunity of being chosen as a part of the sampling process. For example, the total workforce in organisations is 300 and to conduct a survey, a sample group of 30 employees is selected to do the survey. In this case, the population is the total number of employees in the company and the sample group of 30 employees is the sample. Each member of the workforce has an equal opportunity of being chosen because all the employees which were chosen to be part of the survey were selected randomly. But, there is always a possibility that the group or the sample does not represent the population as a whole, in that case, any random variation is termed as a sampling error.\n",
        "\n",
        "An unbiased random sample is important for drawing conclusions. For example when we took out the sample of 30 employees from the total population of 300 employees, there is always a possibility that a researcher might end up picking over 25 men even if the population consists of 200 men and 100 women. Hence, some variations when drawing results can come up, which is known as a sampling error. One of the disadvantages of random sampling is the fact that it requires a complete list of population. For example, if a company wants to carry out a survey and intends to deploy random sampling, in that case, there should be total number of employees and there is a possibility that all the employees are spread across different regions which make the process of survey little difficult.\n",
        "\n",
        "- torch.bernoulli()\n",
        "- torch.Tensor.cauchy_()\n",
        "- torch.poisson()\n",
        "- torch.normal()\n",
        "- torch.rand()\n",
        "\n",
        "Before we begin, let's install and import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QEOQdNHI6Oz"
      },
      "outputs": [],
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "bTH70yR0I6O0"
      },
      "source": [
        "## Function 1 - torch.bernoulli()\n",
        "\n",
        "torch.bernoulli() method is used to draw binary random numbers (0 or 1) from a Bernoulli distribution. This method accepts a tensor as a parameter, and this input tensor is the probability of drawing 1. The values of the input tensor should be in the range of 0 to 1. This method returns a tensor that only has values 0 or 1 and the size of this tensor is the same as the input tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "nAHcWbS_I6O1",
        "outputId": "2a967e9d-7add-41d0-d052-c5b96d6fe95c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0966, 0.7385, 0.6546],\n",
              "        [0.4255, 0.8294, 0.8315],\n",
              "        [0.8065, 0.8228, 0.6467]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.empty(3, 3).uniform_(0, 1)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "RfJECtwbI6O3",
        "outputId": "c9aee4af-b330-4536-ff8b-26dff61aa243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 0., 1.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1 - working \n",
        "torch.bernoulli(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "UAKaUNG2I6O4"
      },
      "source": [
        "The input was a tensor containing probabilities of drawing 1 and hence the function returns corresponding tensor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "7t_sswaII6O5",
        "outputId": "830a7ffd-246d-41e0-eb58-819068147363"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.ones(3, 3) \n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "I84z8JdvI6O6",
        "outputId": "a34edde2-50ee-42f1-e09c-96c497e89a48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2 - working\n",
        "torch.bernoulli(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ltLa0XUFI6O7"
      },
      "source": [
        "As the probabilities were one the function returns a tensor with all elements as 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "NhwNMbkwI6O7",
        "outputId": "270d5efd-2704-4e94-a871-31b4430d91ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1,  2,  5],\n",
              "        [ 3,  4,  5]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "a=torch.tensor([[-1, 2,5], [3, 4, 5]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "UhiYpinEI6O8",
        "outputId": "02884510-ff3d-4a63-bb53-0fe42041fab5"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "\"bernoulli_tensor_cpu_p_\" not implemented for 'Long'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_37/777679872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: \"bernoulli_tensor_cpu_p_\" not implemented for 'Long'"
          ]
        }
      ],
      "source": [
        "torch.bernoulli(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "0RKiww4-I6O8"
      },
      "source": [
        "Probability canot be nagative hence the function fails to return a tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "1zyEU0dcI6O9"
      },
      "source": [
        "The Bernoulli distribution is a discrete distribution having two possible outcomes labelled by and in which (“success”) occurs with probability and (“failure”) occurs with probability , where . It therefore has probability density function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "JdNf6O9dI6PA"
      },
      "source": [
        "## Function 2 - torch.Tensor.cauchy_()\n",
        "\n",
        "Fills the tensor with numbers drawn from the Cauchy distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "L0WQ1w-TI6PA",
        "outputId": "526a8480-4018-490e-d650-02118663135d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.2242e-38,  3.0746e-41, -2.3631e-38],\n",
              "        [ 3.0746e-41,  1.5695e-43,  0.0000e+00],\n",
              "        [ 6.7262e-44,  0.0000e+00, -2.3912e-38]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.empty(3, 3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "u34IKvpuI6PB",
        "outputId": "81811cea-fbd1-42de-d051-98c5b6e4f649"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ -0.3098,  -0.7789,  -1.4854],\n",
              "        [-41.7906,   0.3488,   0.8408],\n",
              "        [ -2.7455,   1.3863,  -0.9825]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.Tensor.cauchy_(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5Qx-nsw0I6PB"
      },
      "source": [
        "The vector with uninitialized data is filled with numbers from a cauchy distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "-qAN_Lh3I6PC",
        "outputId": "258395a5-aa36-4b21-fd81-8e6b58262f8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2 - workinga = torch.ones(3, 3) \n",
        "a = torch.ones(3, 3) \n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "CGy6UI2yI6PC",
        "outputId": "36464d50-ad93-4b79-a303-5530beaf8730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-4.5374,  0.3726,  0.4947],\n",
              "        [ 0.4111,  0.9167,  0.7214],\n",
              "        [ 1.0533, -9.2247,  0.7620]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.Tensor.cauchy_(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "89UaNeHzI6PC"
      },
      "source": [
        "The vector is filled with numbers from a cauchy distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "bWPYzfwzI6PC",
        "outputId": "5b2e8104-3956-4d5c-817a-830e465afd3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1]], dtype=torch.int32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "a = torch.ones(4, 4, dtype = torch.int32)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "NcgLozcNI6PD",
        "outputId": "1fc97efb-ea29-489f-b369-d4087477241a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "\"cauchy_cpu\" not implemented for 'Int'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_37/4217869473.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcauchy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: \"cauchy_cpu\" not implemented for 'Int'"
          ]
        }
      ],
      "source": [
        "torch.Tensor.cauchy_(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "V8B89ZNeI6PD"
      },
      "source": [
        "The input tensor must be floating point datatype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "h32kNDPyI6PD"
      },
      "source": [
        "The Cauchy distribution, sometimes called the Lorentz distribution, is a family of continuous probably distributions which resemble the normal distribution family of curves. While the resemblance is there, it has a taller peak than a normal. And unlike the normal distribution, it’s fat tails decay much more slowly.\n",
        "\n",
        "The Cauchy distribution is well known for the fact that it’s expected value and other moments do not exist. The median and mode do exist. And for the Cauchy, they are equal. Together, they tell you where the line of symmetry is. However, the Central Limit theorem doesn’t work for the limiting distribution of the mean. In sum, this distribution behaves so abnormally it’s sometimes considered the Hannibal Lecter of distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "AZVAj23ZI6PE"
      },
      "source": [
        "## Function 3 - torch.poisson()\n",
        "\n",
        "Returns a tensor of the same size as input with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "bgHGYZ5rI6PE",
        "outputId": "54a2441f-eb86-403f-edb5-a1c95bd5bd2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 1., 0., 8.],\n",
              "        [2., 3., 3., 3.],\n",
              "        [0., 0., 1., 6.],\n",
              "        [0., 5., 3., 3.]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1 - working (from official documentation)\n",
        "a= torch.rand(4, 4) * 5  # rate parameter between 0 and 5\n",
        "torch.poisson(a) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ZP_SJFzAI6PF"
      },
      "source": [
        "Returns a output from a poisson distribution for input tensor containing rate parameter between 0 and 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "PkB5mh7kI6PF",
        "outputId": "c9697cc0-3007-406d-9e7d-31b213fe38be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[10.,  7.,  4.,  3.],\n",
              "        [ 2.,  2.,  7.,  6.],\n",
              "        [ 4.,  0., 10.,  3.],\n",
              "        [ 6.,  1.,  4.,  5.]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2 - working\n",
        "a= torch.rand(4, 4) * 9  # rate parameter between 0 and 9\n",
        "torch.poisson(a) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "xBFnHovkI6PF"
      },
      "source": [
        "Returns a output from a poisson distribution for input tensor containing rate parameter between 0 and 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "fVAmiZe0I6PG",
        "outputId": "61194f5e-c0cc-47bf-a190-d8ae987643ef"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "\"poisson_cpu\" not implemented for 'Int'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_37/2269610702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: \"poisson_cpu\" not implemented for 'Int'"
          ]
        }
      ],
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "a = torch.ones(3,3, dtype = torch.int32)\n",
        "torch.poisson(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "W38j-2PnI6PG"
      },
      "source": [
        "The input tensor must be floating point datatype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "lDnDVGhwI6PG"
      },
      "source": [
        "In Statistics, Poisson distribution is one of the important topics. It is used for calculating the possibilities for an event with the average rate of value. Poisson distribution is a discrete probability distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "DARxlp_LI6PH"
      },
      "source": [
        "## Function 4 - torch.normal()\n",
        "\n",
        "Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.\n",
        "\n",
        "The mean is a tensor with the mean of each output element’s normal distribution\n",
        "\n",
        "The std is a tensor with the standard deviation of each output element’s normal distribution\n",
        "\n",
        "The shapes of mean and std don’t need to match, but the total number of elements in each tensor need to be the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "AEeRvfQJI6PH",
        "outputId": "c5c0a23a-e329-41a2-9f8f-91ece4e25f27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.1424, 1.3351, 3.1882, 3.7897, 3.7148])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1 - working\n",
        "torch.normal(mean=torch.arange(1., 6.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "TchYMplnI6PH"
      },
      "source": [
        "It returns a tensor of random numbers drawn from separate normal distributions whose standard deviation is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "UwgL7Q5eI6PI",
        "outputId": "89158a36-26da-4f87-fb85-79c29cf6f828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.6932,  2.3833,  2.3547,  3.8103,  5.4436,  5.8295,  7.5898,  8.4793,\n",
              "         9.1938, 10.0637])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2 - working\n",
        "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_6Ih9VqqI6PI"
      },
      "source": [
        "It returns a tensor of random numbers drawn from separate normal distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "ZSNA95zOI6PI",
        "outputId": "1beef80c-1b92-4d0f-dd86-14028a248b3c"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "inconsistent tensor, std and mean are not broadcastable and have different number of elements, expected mean [3, 3] and std [4, 3] to have same number of elements)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_37/74183616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor, std and mean are not broadcastable and have different number of elements, expected mean [3, 3] and std [4, 3] to have same number of elements)"
          ]
        }
      ],
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.normal(mean= torch.ones(3,3), std= torch.ones(4,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "M8LWULomI6PI"
      },
      "source": [
        "The number of elements of mean and standard deviation needs to be same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "XPN3DPIFI6PJ"
      },
      "source": [
        "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean.\n",
        "\n",
        "In graphical form, the normal distribution appears as a \"bell curve\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "qmWjJ0VTI6PJ"
      },
      "source": [
        "## Function 5 - torch.rand()\n",
        "\n",
        "Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)[0,1)\n",
        "\n",
        "The shape of the tensor is defined by the variable argument size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "2UUsjd-QI6PJ",
        "outputId": "383f8cbd-234b-42b6-e88e-f7eb3c8452e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.7498,  1.0187, -1.9089, -0.1189])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1 - working\n",
        "torch.randn(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "gzRLcrIzI6PK"
      },
      "source": [
        "The function returns random numbers from standard normal distribution for a given input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "GkjBCtdVI6PK",
        "outputId": "9785a840-7b83-4862-b212-4502ee9f0aaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.3119, -0.2177, -0.2496,  0.2361],\n",
              "        [-1.2755, -0.2271,  1.5297,  0.6433],\n",
              "        [-0.4198, -0.9269, -0.6260, -0.9713],\n",
              "        [ 0.6730, -1.2400,  2.1338,  0.2051]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2 - working\n",
        "torch.randn(4,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "mjPQFAiuI6PK"
      },
      "source": [
        "The function returns random numbers from standard normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "tAIuatn0I6PK",
        "outputId": "5a238193-607d-4c61-b61a-d5a3a270f17b"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "\"normal_kernel_cpu\" not implemented for 'Int'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_37/2949950189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: \"normal_kernel_cpu\" not implemented for 'Int'"
          ]
        }
      ],
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.randn(4, 5, dtype = torch.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "oeJpx89kI6PL"
      },
      "source": [
        "The input tensor must be floating point datatype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "CDsp5RMLI6PL"
      },
      "source": [
        "PyTorch torch.randn() returns a tensor defined by the variable argument size (sequence of integers defining the shape of the output tensor), containing random numbers from standard normal distribution.\n",
        "\n",
        "The standard normal distribution, also called the z-distribution, is a special normal distribution where the mean is 0 and the standard deviation is 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "aAemB66SI6PM"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Data is the currency of applied machine learning. Therefore, it is important that it is both collected and used effectively.\n",
        "\n",
        "Data sampling refers to statistical methods for selecting observations from the domain with the objective of estimating a population parameter. Whereas data resampling refers to methods for economically using a collected dataset to improve the estimate of the population parameter and help to quantify the uncertainty of the estimate.\n",
        "\n",
        "Both data sampling and data resampling are methods that are required in a predictive modeling problem.\n",
        "\n",
        "In this notebook we went through five PyTorch functions for sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doHBYRsRI6PM"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n",
        "* Jonathan Hui blog: https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bmduaxtI6PM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}